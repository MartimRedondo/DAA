{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn import tree\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/test_clean.csv')\n",
    "train = pd.read_csv('datasets/train_clean.csv')\n",
    "\n",
    "#train = pd.read_csv('datasets/controlo_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized = train.copy()\n",
    "test_normalized = test.copy()\n",
    "\n",
    "X_scale = train_normalized.drop(columns=['Transition'])\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0,1)).fit(X_scale)\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1)).fit(test_normalized)\n",
    "X_scale = pd.DataFrame(scaler_X.transform(X_scale[X_scale.columns]), columns=X_scale.columns)\n",
    "test_normalized = pd.DataFrame(scaler_y.transform(test_normalized[test_normalized.columns]), columns=test_normalized.columns)\n",
    "\n",
    "train_normalized = pd.concat([X_scale, train_normalized['Transition']], axis=1)\n",
    "\n",
    "#test_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dados Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Transition'])\n",
    "y = train['Transition']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dados Treino normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nm = train_normalized.drop(columns=['Transition'])\n",
    "y_nm = train_normalized['Transition']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(random_state=2022, class_weight='balanced', n_estimators= 500)\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_model, step=25, cv=cv, scoring='f1_macro',min_features_to_select=50, n_jobs=-1)\n",
    "\n",
    "rfecv.fit(X_nm, y_nm)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "\n",
    "X = X.iloc[:, rfecv.support_]\n",
    "X_nm = X_nm.iloc[:, rfecv.support_]\n",
    "\n",
    "test = test.iloc[:, rfecv.support_]\n",
    "test_normalized = test_normalized.iloc[:, rfecv.support_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_nm = pca.fit_transform(X_nm)\n",
    "test_normalized= pca.transform(test_normalized)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE(podes ou não fazer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampling_strategy = {0.0: 60, 1.0: 96, 2.0: 68, 3.0: 71, 4.0: 40}#só aumenta para 4.0\n",
    "\n",
    "smote = SMOTE(random_state=42,sampling_strategy='auto', k_neighbors = 5)\n",
    "X_nm, y_nm = smote.fit_resample(X_nm, y_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=2022\n",
    ")\n",
    "\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(\n",
    "    X_nm, y_nm, test_size=0.2, random_state=2022, stratify=y_nm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELAÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.10      0.08      0.09        12\n",
      "         1.0       0.53      0.53      0.53        19\n",
      "         2.0       0.20      0.29      0.24        14\n",
      "         3.0       0.25      0.21      0.23        14\n",
      "         4.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.30        61\n",
      "   macro avg       0.22      0.22      0.22        61\n",
      "weighted avg       0.29      0.30      0.29        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=2023)\n",
    "\n",
    "dt_model.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "\n",
    "dt_predictions = dt_model.predict(X_test_nm)\n",
    "\n",
    "print(classification_report(y_test_nm, dt_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.50      0.50        12\n",
      "         1.0       0.58      0.95      0.72        19\n",
      "         2.0       0.20      0.14      0.17        14\n",
      "         3.0       0.38      0.21      0.27        14\n",
      "         4.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.33      0.36      0.33        61\n",
      "weighted avg       0.41      0.48      0.42        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=2023, class_weight='balanced', n_estimators=500)\n",
    "\n",
    "rf_model.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test_nm)\n",
    "\n",
    "print(classification_report(y_test_nm, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.54%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.33      0.35        12\n",
      "         1.0       0.62      0.84      0.71        19\n",
      "         2.0       0.31      0.29      0.30        14\n",
      "         3.0       0.44      0.29      0.35        14\n",
      "         4.0       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.45      0.45      0.44        61\n",
      "weighted avg       0.45      0.48      0.45        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(C=0.1, class_weight='balanced', kernel='linear', random_state=2022)\n",
    "\n",
    "svm_model.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "svm_score = svm_model.score(X_test_nm, y_test_nm)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (svm_score * 100))\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test_nm)\n",
    "\n",
    "print(classification_report(y_test_nm, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.26%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.50      0.48        12\n",
      "         1.0       0.58      0.74      0.65        19\n",
      "         2.0       0.22      0.14      0.17        14\n",
      "         3.0       0.33      0.36      0.34        14\n",
      "         4.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.44        61\n",
      "   macro avg       0.32      0.35      0.33        61\n",
      "weighted avg       0.40      0.44      0.42        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(activation='tanh', alpha=0.01, early_stopping=True,\n",
    "              hidden_layer_sizes=(100, 50), max_iter=1000, random_state=2023,\n",
    "              solver='lbfgs')\n",
    "\n",
    "mlp_model.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "mlp_score = mlp_model.score(X_test_nm, y_test_nm)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (mlp_score * 100))\n",
    "\n",
    "mlp_predictions = mlp_model.predict(X_test_nm)\n",
    "\n",
    "print(classification_report(y_test_nm, mlp_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.02%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.50      0.52        12\n",
      "         1.0       0.61      0.89      0.72        19\n",
      "         2.0       0.50      0.43      0.46        14\n",
      "         3.0       0.70      0.50      0.58        14\n",
      "         4.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.59        61\n",
      "   macro avg       0.47      0.46      0.46        61\n",
      "weighted avg       0.57      0.59      0.57        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/guirio99/miniconda3/envs/daa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(learning_rate=0.01, min_samples_leaf=2,\n",
    "                           n_estimators=500, random_state=2023)\n",
    "\n",
    "gbc_model.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "gbc_score = gbc_model.score(X_test_nm, y_test_nm)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (gbc_score * 100))\n",
    "\n",
    "gbc_predictions = gbc_model.predict(X_test_nm)\n",
    "\n",
    "print(classification_report(y_test_nm, gbc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..................passthrough=True;, score=0.438 total time= 2.5min\n",
      "[CV 2/5] END ..................passthrough=True;, score=0.490 total time= 2.4min\n",
      "[CV 3/5] END ..................passthrough=True;, score=0.451 total time= 2.6min\n",
      "[CV 4/5] END ..................passthrough=True;, score=0.344 total time= 2.7min\n",
      "[CV 5/5] END ..................passthrough=True;, score=0.334 total time= 2.7min\n",
      "Best estimator: StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
      "        random_state=RandomState(MT19937) at 0x7FF12E0DBB40, shuffle=False),\n",
      "                   estimators=[('gbc',\n",
      "                                GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                                           min_samples_leaf=2,\n",
      "                                                           n_estimators=500,\n",
      "                                                           random_state=2023)),\n",
      "                               ('gbc2',\n",
      "                                GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                                           min_samples_leaf=2,\n",
      "                                                           n_estimators=500,\n",
      "                                                           random_state=2023))],\n",
      "                   final_estimator=SVC(C=0.1, class_weight='balanced',\n",
      "                                       kernel='linear', random_state=2022),\n",
      "                   passthrough=True)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.25      0.29        12\n",
      "         1.0       0.63      0.89      0.74        19\n",
      "         2.0       0.31      0.36      0.33        14\n",
      "         3.0       0.62      0.36      0.45        14\n",
      "         4.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.58      0.47      0.50        61\n",
      "weighted avg       0.51      0.51      0.49        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#estimators = [(\"svm\", svm_model), (\"svm2\", svm_model), (\"svm3\", svm_model), (\"svm4\", svm_model), (\"svm5\", svm_model)]\n",
    "#estimators = [ (\"mlp\", mlp_model)]\n",
    "estimators = [ (\"gbc\", gbc_model)]\n",
    "\n",
    "\n",
    "st_model = StackingClassifier(estimators=estimators, final_estimator=svm_model, cv=cv)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'passthrough': [True, False],\n",
    "}\n",
    "\n",
    "grid_st = GridSearchCV(\n",
    "    st_model, \n",
    "    param_grid, \n",
    "    refit=True, \n",
    "    verbose = 3,\n",
    "    scoring= 'f1_macro',\n",
    "    cv=cv\n",
    "    )\n",
    "\n",
    "grid_st.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "predictions = grid_st.predict(X_test_nm)\n",
    "\n",
    "print(\"Best estimator:\", grid_st.best_estimator_)\n",
    "\n",
    "\n",
    "print(classification_report(y_test_nm, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model = grid_st.best_estimator_\n",
    "st_model.fit(X_nm, y_nm)\n",
    "predictionsST = st_model.predict(test_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'AD-AD',\n",
    "    1: 'CN-CN',\n",
    "    2: 'MCI-AD',\n",
    "    3: 'MCI-MCI',\n",
    "    4: 'CN-MCI'\n",
    "}\n",
    "\n",
    "result_labels = [label_mapping[pred] for pred in predictionsST]\n",
    "result_df = pd.DataFrame({\n",
    "    'RowId': range(1, len(predictionsST) + 1),\n",
    "    'Result': result_labels\n",
    "})\n",
    "\n",
    "result_df.to_csv('datasets/stacking.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
