{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn import tree\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/test_clean.csv')\n",
    "train = pd.read_csv('datasets/train_clean.csv')\n",
    "\n",
    "#train = pd.read_csv('datasets/controlo_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized = train.copy()\n",
    "test_normalized = test.copy()\n",
    "\n",
    "X_scale = train_normalized.drop(columns=['Transition'])\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0,1)).fit(X_scale)\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1)).fit(test_normalized)\n",
    "X_scale = pd.DataFrame(scaler_X.transform(X_scale[X_scale.columns]), columns=X_scale.columns)\n",
    "test_normalized = pd.DataFrame(scaler_y.transform(test_normalized[test_normalized.columns]), columns=test_normalized.columns)\n",
    "\n",
    "train_normalized = pd.concat([X_scale, train_normalized['Transition']], axis=1)\n",
    "\n",
    "#test_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dados Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Transition'])\n",
    "y = train['Transition']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dados Treino normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nm = train_normalized.drop(columns=['Transition'])\n",
    "y_nm = train_normalized['Transition']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(random_state=2022, class_weight='balanced', n_estimators= 500)\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_model, step=25, cv=cv, scoring='f1_macro',min_features_to_select=50, n_jobs=-1)\n",
    "\n",
    "rfecv.fit(X_nm, y_nm)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "\n",
    "X = X.iloc[:, rfecv.support_]\n",
    "X_nm = X_nm.iloc[:, rfecv.support_]\n",
    "\n",
    "test = test.iloc[:, rfecv.support_]\n",
    "test_normalized = test_normalized.iloc[:, rfecv.support_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_nm = pca.fit_transform(X_nm)\n",
    "test_normalized= pca.transform(test_normalized)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE(podes ou não fazer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampling_strategy = {0.0: 60, 1.0: 96, 2.0: 68, 3.0: 71, 4.0: 40}#só aumenta para 4.0\n",
    "\n",
    "smote = SMOTE(random_state=42,sampling_strategy=sampling_strategy, k_neighbors = 5)\n",
    "X_nm, y_nm = smote.fit_resample(X_nm, y_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=2022\n",
    ")\n",
    "\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(\n",
    "    X_nm, y_nm, test_size=0.2, random_state=2022, stratify=y_nm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator_xgb = XGBClassifier(random_state=2023, objective='multi:softprob', num_class=5)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [300, 500, 800],\n",
    "    'max_depth': [5],\n",
    "    'gamma': [0.1],\n",
    "    'min_child_weight': [ 2, 5],\n",
    "    'colsample_bytree': [0.6, 1.0]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator_xgb, \n",
    "    param_grid_xgb, \n",
    "    refit=True, \n",
    "    verbose = 3,\n",
    "    scoring= 'f1_macro',\n",
    "    cv=cv\n",
    "    )\n",
    "\n",
    "grid_xgb.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "predictions = grid_xgb.predict(X_test_nm)\n",
    "\n",
    "print(\"Best estimator:\", grid_xgb.best_estimator_)\n",
    "\n",
    "\n",
    "print(classification_report(y_test_nm, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final(usar hiperparametros do gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model = grid_xgb.best_estimator_\n",
    "xgb_model.fit(X_nm, y_nm)\n",
    "predictionsXGB = xgb_model.predict(test_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'AD-AD',\n",
    "    1: 'CN-CN',\n",
    "    2: 'MCI-AD',\n",
    "    3: 'MCI-MCI',\n",
    "    4: 'CN-MCI'\n",
    "}\n",
    "\n",
    "result_labels = [label_mapping[pred] for pred in predictionsXGB]\n",
    "result_df = pd.DataFrame({\n",
    "    'RowId': range(1, len(predictionsXGB) + 1),\n",
    "    'Result': result_labels\n",
    "})\n",
    "\n",
    "result_df.to_csv('datasets/XGB.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
